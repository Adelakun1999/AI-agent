{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23584a36-19f0-4a73-9bea-d99373be0006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import frontmatter\n",
    "import io\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97b8a715-ee7e-4809-85dc-1aeecdcc8f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://codeload.github.com/DataTalksClub/faq/zip/refs/heads/main'\n",
    "resp = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9687164-377b-4314-b8c8-d661586560cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "repository_data = []\n",
    "\n",
    "# Create a ZipFile object from the downloaded content\n",
    "zf = zipfile.ZipFile(io.BytesIO(resp.content))\n",
    "\n",
    "for file_info in zf.infolist():\n",
    "    filename = file_info.filename.lower()\n",
    "    # Only process markdown files\n",
    "    if not filename.endswith('.md'):\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "    # Read and parse each file\n",
    "    with zf.open(file_info) as f_in:\n",
    "        content = f_in.read().decode('utf-8' , errors=\"ignore\")\n",
    "        post = frontmatter.loads(content)\n",
    "        data = post.to_dict()\n",
    "        data['filename'] = filename\n",
    "        repository_data.append(data)\n",
    "\n",
    "zf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02f020b-7111-4dda-93f0-df7c39b6d73e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "acde970c-7b0a-42a4-b97a-979b0f5ae243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '9e508f2212',\n",
       " 'question': 'Course: When does the course start?',\n",
       " 'sort_order': 1,\n",
       " 'content': \"The next cohort starts January 13th, 2025. More info at [DTC](https://datatalks.club/blog/guide-to-free-online-courses-at-datatalks-club.html).\\n\\n- Register before the course starts using this [link](https://airtable.com/shr6oVXeQvSI5HuWD).\\n- Join the [course Telegram channel with announcements](https://t.me/dezoomcamp).\\n- Don‚Äôt forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'filename': 'faq-main/_questions/data-engineering-zoomcamp/general/001_9e508f2212_course-when-does-the-course-start.md'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repository_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "310b083d-c2b0-4ace-9d30-dfb6d8e54f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_repo_data(repo_owner, repo_name):\n",
    "    \"\"\"\n",
    "    Download and parse all markdown files from a GitHub repository.\n",
    "    \n",
    "    Args:\n",
    "        repo_owner: GitHub username or organization\n",
    "        repo_name: Repository name\n",
    "    \n",
    "    Returns:\n",
    "        List of dictionaries containing file content and metadata\n",
    "    \"\"\"\n",
    "    prefix = 'https://codeload.github.com' \n",
    "    url = f'{prefix}/{repo_owner}/{repo_name}/zip/refs/heads/main'\n",
    "    resp = requests.get(url)\n",
    "    \n",
    "    if resp.status_code != 200:\n",
    "        raise Exception(f\"Failed to download repository: {resp.status_code}\")\n",
    "\n",
    "    repository_data = []\n",
    "    zf = zipfile.ZipFile(io.BytesIO(resp.content))\n",
    "    \n",
    "    for file_info in zf.infolist():\n",
    "        filename = file_info.filename\n",
    "        filename_lower = filename.lower()\n",
    "\n",
    "        if not (filename_lower.endswith('.md') \n",
    "            or filename_lower.endswith('.mdx')):\n",
    "            continue\n",
    "    \n",
    "        try:\n",
    "            with zf.open(file_info) as f_in:\n",
    "                content = f_in.read().decode('utf-8', errors='ignore')\n",
    "                post = frontmatter.loads(content)\n",
    "                data = post.to_dict()\n",
    "                data['filename'] = filename\n",
    "                repository_data.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    zf.close()\n",
    "    return repository_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "56925457-34e1-4a47-8208-6d24e6a0d0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_cookbooks = read_repo_data('athina-ai' , 'rag-cookbooks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "56d0ef36-25e0-44d5-8e12-15c7fd80553f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAQ documents: 1219\n",
      "Evidently documents: 95\n"
     ]
    }
   ],
   "source": [
    "dtc_faq = read_repo_data('DataTalksClub', 'faq')\n",
    "evidently_docs = read_repo_data('evidentlyai', 'docs')\n",
    "\n",
    "print(f\"FAQ documents: {len(dtc_faq)}\")\n",
    "print(f\"Evidently documents: {len(evidently_docs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5fb345fc-ab02-465e-96f7-73bc351057cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[![LinkedIn](https://img.shields.io/badge/LinkedIn-follow-blue)](https://www.linkedin.com/company/athina-ai/posts/?feedView=all)&nbsp;\\n[![Twitter](https://img.shields.io/twitter/follow/AthinaAI?label=Follow%20@AthinaAI&style=social)](https://x.com/AthinaAI)&nbsp;\\n[![Share](https://img.shields.io/badge/share-000000?logo=x&logoColor=white)](https://x.com/intent/tweet?text=Check%20out%20this%20project%20on%20GitHub:%20https://github.com/athina-ai/rag-cookbooks)&nbsp;\\n[![Share](https://img.shields.io/badge/share-0A66C2?logo=linkedin&logoColor=white)](https://www.linkedin.com/sharing/share-offsite/?url=https://github.com/athina-ai/rag-cookbooks)&nbsp;\\n[![Share](https://img.shields.io/badge/share-FF4500?logo=reddit&logoColor=white)](https://www.reddit.com/submit?title=Check%20out%20this%20project%20on%20GitHub:%20https://github.com/athina-ai/rag-cookbooks)\\n\\n>If you find this repository helpful, please consider giving it a star‚≠êÔ∏è\\n\\n# Advanced + Agentic RAG Cookbooksüë®üèª\\u200düíª\\nWelcome to the comprehensive collection of advanced + agentic Retrieval-Augmented Generation (RAG) techniques.\\n\\n## IntroductionüöÄ\\nRAG is a popular method that improves accuracy and relevance by finding the right information from reliable sources and transforming it into useful answers. This repository covers the most effective advanced + agentic RAG techniques with clear implementations and explanations.\\n\\nThe main goal of this repository is to provide a helpful resource for researchers and developers looking to use advanced RAG techniques in their projects. Building these techniques from scratch takes time, and finding proper evaluation methods can be challenging. This repository simplifies the process by offering ready-to-use implementations and guidance on how to evaluate them.\\n>[!NOTE]\\n>This repository starts with naive RAG as a foundation and progresses to advanced and agentic techniques. It also includes research papers/references for each RAG technique, which you can explore for further reading.\\n\\n## Introduction to RAGüí°\\nLarge Language Models are trained on a fixed dataset, which limits their ability to handle private or recent information. They can sometimes \"hallucinate\", providing incorrect yet believable answers. Fine-tuning can help but it is expensive and not ideal for retraining again and again on new data. The Retrieval-Augmented Generation (RAG) framework addresses this issue by using external documents to improve the LLM\\'s responses through in-context learning. RAG ensures that the information provided by the LLM is not only contextually relevant but also accurate and up-to-date.\\n\\n![final diagram](https://github.com/user-attachments/assets/508b3a87-ac46-4bf7-b849-145c5465a6c0)\\n\\nThere are four main components in RAG:\\n\\n**Indexing:** First, documents (in any format) are split into chunks, and embeddings for these chunks are created. These embeddings are then added to a vector store.\\n\\n**Retriever:** Then, the retriever finds the most relevant documents based on the user\\'s query, using techniques like vector similarity from the vector store.\\n\\n**Augment:** After that, the Augment part combines the user\\'s query with the retrieved context into a prompt, ensuring the LLM has the information needed to generate accurate responses.\\n\\n**Generate:** Finally, the combined query and prompt are passed to the model, which then generates the final response to the user\\'s query.\\n\\nThese components of RAG allow the model to access up-to-date, accurate information and generate responses based on external knowledge. However, to ensure RAG systems are functioning effectively, it‚Äôs essential to evaluate their performance.\\n\\n## RAG Evaluationüìä\\nEvaluating RAG applications is important for understanding how well these systems work. We can see how effectively they combine information retrieval with generative models by checking their accuracy and relevance. This evaluation helps improve RAG applications in tasks like text summarization, chatbots, and question-answering. It also identifies areas for improvement, ensuring that these systems provide trustworthy responses as information changes. Overall, effective evaluation helps optimize performance and builds confidence in RAG applications for real-world use. These notebooks contain an end-to-end RAG implementation + RAG evaluation part in Athina AI.\\n\\n![evals diagram](https://github.com/user-attachments/assets/65c2b5af-a931-40c5-b006-87567aef019f)\\n\\n\\n\\n## Advanced RAG Techniques‚öôÔ∏è\\nHere are the details of all the Advanced RAG techniques covered in this repository.\\n\\n| Technique                    | Tools                        | Description                                                       | Notebooks |\\n|---------------------------------|------------------------------|--------------------------------------------------------------|-----------|\\n| Naive RAG      | LangChain, Pinecone, Athina AI                    | Combines retrieved data with LLMs for simple and effective responses.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/naive_rag.ipynb) |\\n| Hybrid RAG      | LangChain, Chromadb, Athina AI                    | Combines vector search and traditional methods like BM25 for better information retrieval.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/hybrid_rag.ipynb) |\\n| Hyde RAG      | LangChain, Weaviate, Athina AI                    | Creates hypothetical document embeddings to find relevant information for a query.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/hyde_rag.ipynb) |\\n| Parent Document Retriever      | LangChain, Chromadb, Athina AI                    | Breaks large documents into small parts and retrieves the full document if a part matches the query.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/parent_document_retriever.ipynb) |\\n| RAG fusion      | LangChain, LangSmith, Qdrant, Athina AI                    | Generates sub-queries, ranks documents with Reciprocal Rank Fusion, and uses top results for accurate responses.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/fusion_rag.ipynb) |\\n| Contextual RAG      | LangChain, Chromadb, Athina AI                    | Compresses retrieved documents to keep only relevant details for concise and accurate responses.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/contextual_rag.ipynb) |\\n| Rewrite Retrieve Read     | LangChain, Chromadb, Athina AI                    | Improves query, retrieves better data, and generates accurate answers.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/rewrite_retrieve_read.ipynb) |\\n| Unstructured RAG     | LangChain, LangGraph, FAISS, Athina AI, Unstructured                    | This method designed to handle documents that combine text, tables, and images.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/basic_unstructured_rag.ipynb) |\\n\\n## Agentic RAG Techniques‚öôÔ∏è\\nHere are the details of all the Agentic RAG techniques covered in this repository.\\n\\n| Technique                    | Tools                        | Description                                                       | Notebooks |\\n|---------------------------------|------------------------------|--------------------------------------------------------------|-----------|\\n| Basic Agentic RAG      | LangChain, FAISS, Athina AI                    | Agentic RAG uses AI agents to find and generate answers using tools like vectordb and web searches.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/agentic_rag_techniques/basic_agentic_rag.ipynb) |\\n| Corrective RAG      | LangChain, LangGraph, Chromadb, Athina AI                    | Refines relevant documents, removes irrelevant ones or does the web search.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/agentic_rag_techniques/corrective_rag.ipynb) |\\n| Self RAG     | LangChain, LangGraph, FAISS, Athina AI                    | Reflects on retrieved data to ensure accurate and complete responses.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/agentic_rag_techniques/self_rag.ipynb) |\\n| Adaptive RAG      | LangChain, LangGraph, FAISS, Athina AI                    | Adjusts retrieval methods based on query type, using indexed data or web search.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/agentic_rag_techniques/adaptive_rag.ipynb) |\\n| ReAct RAG      | LangChain, LangGraph, FAISS, Athina AI                    |  System combining reasoning and retrieval for context-aware responses| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/agentic_rag_techniques/react_rag.ipynb) |\\n\\n## Demoüé¨\\nA quick demo of how each notebook works:\\n\\nhttps://github.com/user-attachments/assets/c6f17961-40a1-4cca-ab1f-2c8fa3d71a7a\\n\\n## Getting Startedüõ†Ô∏è\\nFirst, clone this repository by using the following command:\\n```bash\\ngit clone https://github.com/athina-ai/rag-cookbooks.git\\n```\\nNext, navigate to the project directory:\\n```bash\\ncd rag-cookbooks\\n```\\nOnce you are in the \\'rag-cookbooks\\' directory, follow the detailed implementation for each technique.\\n\\n## Creators + Contributorsüë®üèª\\u200düíª\\n[![Contributors](https://contrib.rocks/image?repo=athina-ai/cookbooks)](https://github.com/athina-ai/cookbooks/graphs/contributors)\\n\\n## Contributingü§ù\\nIf you have a new technique or improvement to suggest, we welcome contributions from the community!\\n\\n## Licenseüìù\\nThis project is licensed under [MIT License](LICENSE)'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_cookbooks[0]['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3175ce-6676-4b93-a875-f251f78b3d89",
   "metadata": {},
   "source": [
    "## Day 2 Chunking  and Intelligent Processing for Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51ac073-3879-4c7e-a59d-914b178c2714",
   "metadata": {},
   "source": [
    "## 1 Simple Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "59a2793e-ddbf-434b-bba5-df748ea25b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(seq , size , step):\n",
    "    if size <=0 or step <=0:\n",
    "        raise ValueError(\"size and step must be positive\")\n",
    "    n = len(seq)\n",
    "    result = []\n",
    "    for i in range(0 , n , step):\n",
    "        chunk = seq[i:i+size]\n",
    "        result.append({'start' : i , 'chunk' : chunk})\n",
    "        if i + size >=n:\n",
    "            break \n",
    "            \n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "557b2621-4fe0-4834-a2f1-8615de2580a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = sliding_window(rag_cookbooks[0]['content'] , 2000 , 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "302c32f9-5b58-4648-b3af-b4266cd5c02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start': 0,\n",
       "  'chunk': '[![LinkedIn](https://img.shields.io/badge/LinkedIn-follow-blue)](https://www.linkedin.com/company/athina-ai/posts/?feedView=all)&nbsp;\\n[![Twitter](https://img.shields.io/twitter/follow/AthinaAI?label=Follow%20@AthinaAI&style=social)](https://x.com/AthinaAI)&nbsp;\\n[![Share](https://img.shields.io/badge/share-000000?logo=x&logoColor=white)](https://x.com/intent/tweet?text=Check%20out%20this%20project%20on%20GitHub:%20https://github.com/athina-ai/rag-cookbooks)&nbsp;\\n[![Share](https://img.shields.io/badge/share-0A66C2?logo=linkedin&logoColor=white)](https://www.linkedin.com/sharing/share-offsite/?url=https://github.com/athina-ai/rag-cookbooks)&nbsp;\\n[![Share](https://img.shields.io/badge/share-FF4500?logo=reddit&logoColor=white)](https://www.reddit.com/submit?title=Check%20out%20this%20project%20on%20GitHub:%20https://github.com/athina-ai/rag-cookbooks)\\n\\n>If you find this repository helpful, please consider giving it a star‚≠êÔ∏è\\n\\n# Advanced + Agentic RAG Cookbooksüë®üèª\\u200düíª\\nWelcome to the comprehensive collection of advanced + agentic Retrieval-Augmented Generation (RAG) techniques.\\n\\n## IntroductionüöÄ\\nRAG is a popular method that improves accuracy and relevance by finding the right information from reliable sources and transforming it into useful answers. This repository covers the most effective advanced + agentic RAG techniques with clear implementations and explanations.\\n\\nThe main goal of this repository is to provide a helpful resource for researchers and developers looking to use advanced RAG techniques in their projects. Building these techniques from scratch takes time, and finding proper evaluation methods can be challenging. This repository simplifies the process by offering ready-to-use implementations and guidance on how to evaluate them.\\n>[!NOTE]\\n>This repository starts with naive RAG as a foundation and progresses to advanced and agentic techniques. It also includes research papers/references for each RAG technique, which you can explore for further reading.\\n\\n## Int'},\n",
       " {'start': 1000,\n",
       "  'chunk': 'nsive collection of advanced + agentic Retrieval-Augmented Generation (RAG) techniques.\\n\\n## IntroductionüöÄ\\nRAG is a popular method that improves accuracy and relevance by finding the right information from reliable sources and transforming it into useful answers. This repository covers the most effective advanced + agentic RAG techniques with clear implementations and explanations.\\n\\nThe main goal of this repository is to provide a helpful resource for researchers and developers looking to use advanced RAG techniques in their projects. Building these techniques from scratch takes time, and finding proper evaluation methods can be challenging. This repository simplifies the process by offering ready-to-use implementations and guidance on how to evaluate them.\\n>[!NOTE]\\n>This repository starts with naive RAG as a foundation and progresses to advanced and agentic techniques. It also includes research papers/references for each RAG technique, which you can explore for further reading.\\n\\n## Introduction to RAGüí°\\nLarge Language Models are trained on a fixed dataset, which limits their ability to handle private or recent information. They can sometimes \"hallucinate\", providing incorrect yet believable answers. Fine-tuning can help but it is expensive and not ideal for retraining again and again on new data. The Retrieval-Augmented Generation (RAG) framework addresses this issue by using external documents to improve the LLM\\'s responses through in-context learning. RAG ensures that the information provided by the LLM is not only contextually relevant but also accurate and up-to-date.\\n\\n![final diagram](https://github.com/user-attachments/assets/508b3a87-ac46-4bf7-b849-145c5465a6c0)\\n\\nThere are four main components in RAG:\\n\\n**Indexing:** First, documents (in any format) are split into chunks, and embeddings for these chunks are created. These embeddings are then added to a vector store.\\n\\n**Retriever:** Then, the retriever finds the most relevant documents based on the user\\'s query,'},\n",
       " {'start': 2000,\n",
       "  'chunk': 'roduction to RAGüí°\\nLarge Language Models are trained on a fixed dataset, which limits their ability to handle private or recent information. They can sometimes \"hallucinate\", providing incorrect yet believable answers. Fine-tuning can help but it is expensive and not ideal for retraining again and again on new data. The Retrieval-Augmented Generation (RAG) framework addresses this issue by using external documents to improve the LLM\\'s responses through in-context learning. RAG ensures that the information provided by the LLM is not only contextually relevant but also accurate and up-to-date.\\n\\n![final diagram](https://github.com/user-attachments/assets/508b3a87-ac46-4bf7-b849-145c5465a6c0)\\n\\nThere are four main components in RAG:\\n\\n**Indexing:** First, documents (in any format) are split into chunks, and embeddings for these chunks are created. These embeddings are then added to a vector store.\\n\\n**Retriever:** Then, the retriever finds the most relevant documents based on the user\\'s query, using techniques like vector similarity from the vector store.\\n\\n**Augment:** After that, the Augment part combines the user\\'s query with the retrieved context into a prompt, ensuring the LLM has the information needed to generate accurate responses.\\n\\n**Generate:** Finally, the combined query and prompt are passed to the model, which then generates the final response to the user\\'s query.\\n\\nThese components of RAG allow the model to access up-to-date, accurate information and generate responses based on external knowledge. However, to ensure RAG systems are functioning effectively, it‚Äôs essential to evaluate their performance.\\n\\n## RAG Evaluationüìä\\nEvaluating RAG applications is important for understanding how well these systems work. We can see how effectively they combine information retrieval with generative models by checking their accuracy and relevance. This evaluation helps improve RAG applications in tasks like text summarization, chatbots, and question-answering. It also identifie'},\n",
       " {'start': 3000,\n",
       "  'chunk': \" using techniques like vector similarity from the vector store.\\n\\n**Augment:** After that, the Augment part combines the user's query with the retrieved context into a prompt, ensuring the LLM has the information needed to generate accurate responses.\\n\\n**Generate:** Finally, the combined query and prompt are passed to the model, which then generates the final response to the user's query.\\n\\nThese components of RAG allow the model to access up-to-date, accurate information and generate responses based on external knowledge. However, to ensure RAG systems are functioning effectively, it‚Äôs essential to evaluate their performance.\\n\\n## RAG Evaluationüìä\\nEvaluating RAG applications is important for understanding how well these systems work. We can see how effectively they combine information retrieval with generative models by checking their accuracy and relevance. This evaluation helps improve RAG applications in tasks like text summarization, chatbots, and question-answering. It also identifies areas for improvement, ensuring that these systems provide trustworthy responses as information changes. Overall, effective evaluation helps optimize performance and builds confidence in RAG applications for real-world use. These notebooks contain an end-to-end RAG implementation + RAG evaluation part in Athina AI.\\n\\n![evals diagram](https://github.com/user-attachments/assets/65c2b5af-a931-40c5-b006-87567aef019f)\\n\\n\\n\\n## Advanced RAG Techniques‚öôÔ∏è\\nHere are the details of all the Advanced RAG techniques covered in this repository.\\n\\n| Technique                    | Tools                        | Description                                                       | Notebooks |\\n|---------------------------------|------------------------------|--------------------------------------------------------------|-----------|\\n| Naive RAG      | LangChain, Pinecone, Athina AI                    | Combines retrieved data with LLMs for simple and effective responses.| [![Open In Colab](https://colab.resea\"},\n",
       " {'start': 4000,\n",
       "  'chunk': 's areas for improvement, ensuring that these systems provide trustworthy responses as information changes. Overall, effective evaluation helps optimize performance and builds confidence in RAG applications for real-world use. These notebooks contain an end-to-end RAG implementation + RAG evaluation part in Athina AI.\\n\\n![evals diagram](https://github.com/user-attachments/assets/65c2b5af-a931-40c5-b006-87567aef019f)\\n\\n\\n\\n## Advanced RAG Techniques‚öôÔ∏è\\nHere are the details of all the Advanced RAG techniques covered in this repository.\\n\\n| Technique                    | Tools                        | Description                                                       | Notebooks |\\n|---------------------------------|------------------------------|--------------------------------------------------------------|-----------|\\n| Naive RAG      | LangChain, Pinecone, Athina AI                    | Combines retrieved data with LLMs for simple and effective responses.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/naive_rag.ipynb) |\\n| Hybrid RAG      | LangChain, Chromadb, Athina AI                    | Combines vector search and traditional methods like BM25 for better information retrieval.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/hybrid_rag.ipynb) |\\n| Hyde RAG      | LangChain, Weaviate, Athina AI                    | Creates hypothetical document embeddings to find relevant information for a query.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/hyde_rag.ipynb) |\\n| Parent Document Retriever      | LangChain, Chromadb, Athina AI                    | Breaks large documents into small parts and ret'},\n",
       " {'start': 5000,\n",
       "  'chunk': 'rch.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/naive_rag.ipynb) |\\n| Hybrid RAG      | LangChain, Chromadb, Athina AI                    | Combines vector search and traditional methods like BM25 for better information retrieval.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/hybrid_rag.ipynb) |\\n| Hyde RAG      | LangChain, Weaviate, Athina AI                    | Creates hypothetical document embeddings to find relevant information for a query.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/hyde_rag.ipynb) |\\n| Parent Document Retriever      | LangChain, Chromadb, Athina AI                    | Breaks large documents into small parts and retrieves the full document if a part matches the query.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/parent_document_retriever.ipynb) |\\n| RAG fusion      | LangChain, LangSmith, Qdrant, Athina AI                    | Generates sub-queries, ranks documents with Reciprocal Rank Fusion, and uses top results for accurate responses.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/fusion_rag.ipynb) |\\n| Contextual RAG      | LangChain, Chromadb, Athina AI                    | Compresses retrieved documents to keep only relevant details for concise and accurate responses.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_tech'},\n",
       " {'start': 6000,\n",
       "  'chunk': 'rieves the full document if a part matches the query.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/parent_document_retriever.ipynb) |\\n| RAG fusion      | LangChain, LangSmith, Qdrant, Athina AI                    | Generates sub-queries, ranks documents with Reciprocal Rank Fusion, and uses top results for accurate responses.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/fusion_rag.ipynb) |\\n| Contextual RAG      | LangChain, Chromadb, Athina AI                    | Compresses retrieved documents to keep only relevant details for concise and accurate responses.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/contextual_rag.ipynb) |\\n| Rewrite Retrieve Read     | LangChain, Chromadb, Athina AI                    | Improves query, retrieves better data, and generates accurate answers.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/rewrite_retrieve_read.ipynb) |\\n| Unstructured RAG     | LangChain, LangGraph, FAISS, Athina AI, Unstructured                    | This method designed to handle documents that combine text, tables, and images.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/basic_unstructured_rag.ipynb) |\\n\\n## Agentic RAG Techniques‚öôÔ∏è\\nHere are the details of all the Agentic RAG techniques covered in this repository.\\n\\n| Technique                    | Tools                        | Description                                '},\n",
       " {'start': 7000,\n",
       "  'chunk': 'niques/contextual_rag.ipynb) |\\n| Rewrite Retrieve Read     | LangChain, Chromadb, Athina AI                    | Improves query, retrieves better data, and generates accurate answers.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/rewrite_retrieve_read.ipynb) |\\n| Unstructured RAG     | LangChain, LangGraph, FAISS, Athina AI, Unstructured                    | This method designed to handle documents that combine text, tables, and images.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/basic_unstructured_rag.ipynb) |\\n\\n## Agentic RAG Techniques‚öôÔ∏è\\nHere are the details of all the Agentic RAG techniques covered in this repository.\\n\\n| Technique                    | Tools                        | Description                                                       | Notebooks |\\n|---------------------------------|------------------------------|--------------------------------------------------------------|-----------|\\n| Basic Agentic RAG      | LangChain, FAISS, Athina AI                    | Agentic RAG uses AI agents to find and generate answers using tools like vectordb and web searches.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/agentic_rag_techniques/basic_agentic_rag.ipynb) |\\n| Corrective RAG      | LangChain, LangGraph, Chromadb, Athina AI                    | Refines relevant documents, removes irrelevant ones or does the web search.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/agentic_rag_techniques/corrective_rag.ipynb) |\\n| Self RAG     | LangChain, LangGraph, FAISS, Athina AI                    | Re'},\n",
       " {'start': 8000,\n",
       "  'chunk': '                       | Notebooks |\\n|---------------------------------|------------------------------|--------------------------------------------------------------|-----------|\\n| Basic Agentic RAG      | LangChain, FAISS, Athina AI                    | Agentic RAG uses AI agents to find and generate answers using tools like vectordb and web searches.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/agentic_rag_techniques/basic_agentic_rag.ipynb) |\\n| Corrective RAG      | LangChain, LangGraph, Chromadb, Athina AI                    | Refines relevant documents, removes irrelevant ones or does the web search.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/agentic_rag_techniques/corrective_rag.ipynb) |\\n| Self RAG     | LangChain, LangGraph, FAISS, Athina AI                    | Reflects on retrieved data to ensure accurate and complete responses.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/agentic_rag_techniques/self_rag.ipynb) |\\n| Adaptive RAG      | LangChain, LangGraph, FAISS, Athina AI                    | Adjusts retrieval methods based on query type, using indexed data or web search.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/agentic_rag_techniques/adaptive_rag.ipynb) |\\n| ReAct RAG      | LangChain, LangGraph, FAISS, Athina AI                    |  System combining reasoning and retrieval for context-aware responses| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/agentic_rag_techniques/react_rag.ipynb) |\\n\\n## Demoüé¨\\nA quick demo of how eac'},\n",
       " {'start': 9000,\n",
       "  'chunk': \"flects on retrieved data to ensure accurate and complete responses.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/agentic_rag_techniques/self_rag.ipynb) |\\n| Adaptive RAG      | LangChain, LangGraph, FAISS, Athina AI                    | Adjusts retrieval methods based on query type, using indexed data or web search.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/agentic_rag_techniques/adaptive_rag.ipynb) |\\n| ReAct RAG      | LangChain, LangGraph, FAISS, Athina AI                    |  System combining reasoning and retrieval for context-aware responses| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/agentic_rag_techniques/react_rag.ipynb) |\\n\\n## Demoüé¨\\nA quick demo of how each notebook works:\\n\\nhttps://github.com/user-attachments/assets/c6f17961-40a1-4cca-ab1f-2c8fa3d71a7a\\n\\n## Getting Startedüõ†Ô∏è\\nFirst, clone this repository by using the following command:\\n```bash\\ngit clone https://github.com/athina-ai/rag-cookbooks.git\\n```\\nNext, navigate to the project directory:\\n```bash\\ncd rag-cookbooks\\n```\\nOnce you are in the 'rag-cookbooks' directory, follow the detailed implementation for each technique.\\n\\n## Creators + Contributorsüë®üèª\\u200düíª\\n[![Contributors](https://contrib.rocks/image?repo=athina-ai/cookbooks)](https://github.com/athina-ai/cookbooks/graphs/contributors)\\n\\n## Contributingü§ù\\nIf you have a new technique or improvement to suggest, we welcome contributions from the community!\\n\\n## Licenseüìù\\nThis project is licensed under [MIT License](LICENSE)\"}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "20e1c448-6a42-48a4-9439-99ce29b1dac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "13fa6228-8c3a-4087-8e75-05615243d652",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chunks = []\n",
    "\n",
    "for doc in rag_cookbooks:\n",
    "    doc_copy = doc.copy()\n",
    "    doc_content = doc_copy.pop('content')\n",
    "    chunks = sliding_window(doc_content ,2000 , 1000)\n",
    "    for chunk in chunks:\n",
    "        chunk.update(doc_copy)\n",
    "    rag_chunks.extend(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d00385d4-56c8-48ac-9def-30e8ae3ab692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start': 0,\n",
       "  'chunk': '[![LinkedIn](https://img.shields.io/badge/LinkedIn-follow-blue)](https://www.linkedin.com/company/athina-ai/posts/?feedView=all)&nbsp;\\n[![Twitter](https://img.shields.io/twitter/follow/AthinaAI?label=Follow%20@AthinaAI&style=social)](https://x.com/AthinaAI)&nbsp;\\n[![Share](https://img.shields.io/badge/share-000000?logo=x&logoColor=white)](https://x.com/intent/tweet?text=Check%20out%20this%20project%20on%20GitHub:%20https://github.com/athina-ai/rag-cookbooks)&nbsp;\\n[![Share](https://img.shields.io/badge/share-0A66C2?logo=linkedin&logoColor=white)](https://www.linkedin.com/sharing/share-offsite/?url=https://github.com/athina-ai/rag-cookbooks)&nbsp;\\n[![Share](https://img.shields.io/badge/share-FF4500?logo=reddit&logoColor=white)](https://www.reddit.com/submit?title=Check%20out%20this%20project%20on%20GitHub:%20https://github.com/athina-ai/rag-cookbooks)\\n\\n>If you find this repository helpful, please consider giving it a star‚≠êÔ∏è\\n\\n# Advanced + Agentic RAG Cookbooksüë®üèª\\u200düíª\\nWelcome to the comprehensive collection of advanced + agentic Retrieval-Augmented Generation (RAG) techniques.\\n\\n## IntroductionüöÄ\\nRAG is a popular method that improves accuracy and relevance by finding the right information from reliable sources and transforming it into useful answers. This repository covers the most effective advanced + agentic RAG techniques with clear implementations and explanations.\\n\\nThe main goal of this repository is to provide a helpful resource for researchers and developers looking to use advanced RAG techniques in their projects. Building these techniques from scratch takes time, and finding proper evaluation methods can be challenging. This repository simplifies the process by offering ready-to-use implementations and guidance on how to evaluate them.\\n>[!NOTE]\\n>This repository starts with naive RAG as a foundation and progresses to advanced and agentic techniques. It also includes research papers/references for each RAG technique, which you can explore for further reading.\\n\\n## Int',\n",
       "  'filename': 'rag-cookbooks-main/README.md'},\n",
       " {'start': 1000,\n",
       "  'chunk': 'nsive collection of advanced + agentic Retrieval-Augmented Generation (RAG) techniques.\\n\\n## IntroductionüöÄ\\nRAG is a popular method that improves accuracy and relevance by finding the right information from reliable sources and transforming it into useful answers. This repository covers the most effective advanced + agentic RAG techniques with clear implementations and explanations.\\n\\nThe main goal of this repository is to provide a helpful resource for researchers and developers looking to use advanced RAG techniques in their projects. Building these techniques from scratch takes time, and finding proper evaluation methods can be challenging. This repository simplifies the process by offering ready-to-use implementations and guidance on how to evaluate them.\\n>[!NOTE]\\n>This repository starts with naive RAG as a foundation and progresses to advanced and agentic techniques. It also includes research papers/references for each RAG technique, which you can explore for further reading.\\n\\n## Introduction to RAGüí°\\nLarge Language Models are trained on a fixed dataset, which limits their ability to handle private or recent information. They can sometimes \"hallucinate\", providing incorrect yet believable answers. Fine-tuning can help but it is expensive and not ideal for retraining again and again on new data. The Retrieval-Augmented Generation (RAG) framework addresses this issue by using external documents to improve the LLM\\'s responses through in-context learning. RAG ensures that the information provided by the LLM is not only contextually relevant but also accurate and up-to-date.\\n\\n![final diagram](https://github.com/user-attachments/assets/508b3a87-ac46-4bf7-b849-145c5465a6c0)\\n\\nThere are four main components in RAG:\\n\\n**Indexing:** First, documents (in any format) are split into chunks, and embeddings for these chunks are created. These embeddings are then added to a vector store.\\n\\n**Retriever:** Then, the retriever finds the most relevant documents based on the user\\'s query,',\n",
       "  'filename': 'rag-cookbooks-main/README.md'},\n",
       " {'start': 2000,\n",
       "  'chunk': 'roduction to RAGüí°\\nLarge Language Models are trained on a fixed dataset, which limits their ability to handle private or recent information. They can sometimes \"hallucinate\", providing incorrect yet believable answers. Fine-tuning can help but it is expensive and not ideal for retraining again and again on new data. The Retrieval-Augmented Generation (RAG) framework addresses this issue by using external documents to improve the LLM\\'s responses through in-context learning. RAG ensures that the information provided by the LLM is not only contextually relevant but also accurate and up-to-date.\\n\\n![final diagram](https://github.com/user-attachments/assets/508b3a87-ac46-4bf7-b849-145c5465a6c0)\\n\\nThere are four main components in RAG:\\n\\n**Indexing:** First, documents (in any format) are split into chunks, and embeddings for these chunks are created. These embeddings are then added to a vector store.\\n\\n**Retriever:** Then, the retriever finds the most relevant documents based on the user\\'s query, using techniques like vector similarity from the vector store.\\n\\n**Augment:** After that, the Augment part combines the user\\'s query with the retrieved context into a prompt, ensuring the LLM has the information needed to generate accurate responses.\\n\\n**Generate:** Finally, the combined query and prompt are passed to the model, which then generates the final response to the user\\'s query.\\n\\nThese components of RAG allow the model to access up-to-date, accurate information and generate responses based on external knowledge. However, to ensure RAG systems are functioning effectively, it‚Äôs essential to evaluate their performance.\\n\\n## RAG Evaluationüìä\\nEvaluating RAG applications is important for understanding how well these systems work. We can see how effectively they combine information retrieval with generative models by checking their accuracy and relevance. This evaluation helps improve RAG applications in tasks like text summarization, chatbots, and question-answering. It also identifie',\n",
       "  'filename': 'rag-cookbooks-main/README.md'},\n",
       " {'start': 3000,\n",
       "  'chunk': \" using techniques like vector similarity from the vector store.\\n\\n**Augment:** After that, the Augment part combines the user's query with the retrieved context into a prompt, ensuring the LLM has the information needed to generate accurate responses.\\n\\n**Generate:** Finally, the combined query and prompt are passed to the model, which then generates the final response to the user's query.\\n\\nThese components of RAG allow the model to access up-to-date, accurate information and generate responses based on external knowledge. However, to ensure RAG systems are functioning effectively, it‚Äôs essential to evaluate their performance.\\n\\n## RAG Evaluationüìä\\nEvaluating RAG applications is important for understanding how well these systems work. We can see how effectively they combine information retrieval with generative models by checking their accuracy and relevance. This evaluation helps improve RAG applications in tasks like text summarization, chatbots, and question-answering. It also identifies areas for improvement, ensuring that these systems provide trustworthy responses as information changes. Overall, effective evaluation helps optimize performance and builds confidence in RAG applications for real-world use. These notebooks contain an end-to-end RAG implementation + RAG evaluation part in Athina AI.\\n\\n![evals diagram](https://github.com/user-attachments/assets/65c2b5af-a931-40c5-b006-87567aef019f)\\n\\n\\n\\n## Advanced RAG Techniques‚öôÔ∏è\\nHere are the details of all the Advanced RAG techniques covered in this repository.\\n\\n| Technique                    | Tools                        | Description                                                       | Notebooks |\\n|---------------------------------|------------------------------|--------------------------------------------------------------|-----------|\\n| Naive RAG      | LangChain, Pinecone, Athina AI                    | Combines retrieved data with LLMs for simple and effective responses.| [![Open In Colab](https://colab.resea\",\n",
       "  'filename': 'rag-cookbooks-main/README.md'},\n",
       " {'start': 4000,\n",
       "  'chunk': 's areas for improvement, ensuring that these systems provide trustworthy responses as information changes. Overall, effective evaluation helps optimize performance and builds confidence in RAG applications for real-world use. These notebooks contain an end-to-end RAG implementation + RAG evaluation part in Athina AI.\\n\\n![evals diagram](https://github.com/user-attachments/assets/65c2b5af-a931-40c5-b006-87567aef019f)\\n\\n\\n\\n## Advanced RAG Techniques‚öôÔ∏è\\nHere are the details of all the Advanced RAG techniques covered in this repository.\\n\\n| Technique                    | Tools                        | Description                                                       | Notebooks |\\n|---------------------------------|------------------------------|--------------------------------------------------------------|-----------|\\n| Naive RAG      | LangChain, Pinecone, Athina AI                    | Combines retrieved data with LLMs for simple and effective responses.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/naive_rag.ipynb) |\\n| Hybrid RAG      | LangChain, Chromadb, Athina AI                    | Combines vector search and traditional methods like BM25 for better information retrieval.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/hybrid_rag.ipynb) |\\n| Hyde RAG      | LangChain, Weaviate, Athina AI                    | Creates hypothetical document embeddings to find relevant information for a query.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/hyde_rag.ipynb) |\\n| Parent Document Retriever      | LangChain, Chromadb, Athina AI                    | Breaks large documents into small parts and ret',\n",
       "  'filename': 'rag-cookbooks-main/README.md'},\n",
       " {'start': 5000,\n",
       "  'chunk': 'rch.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/naive_rag.ipynb) |\\n| Hybrid RAG      | LangChain, Chromadb, Athina AI                    | Combines vector search and traditional methods like BM25 for better information retrieval.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/hybrid_rag.ipynb) |\\n| Hyde RAG      | LangChain, Weaviate, Athina AI                    | Creates hypothetical document embeddings to find relevant information for a query.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/hyde_rag.ipynb) |\\n| Parent Document Retriever      | LangChain, Chromadb, Athina AI                    | Breaks large documents into small parts and retrieves the full document if a part matches the query.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/parent_document_retriever.ipynb) |\\n| RAG fusion      | LangChain, LangSmith, Qdrant, Athina AI                    | Generates sub-queries, ranks documents with Reciprocal Rank Fusion, and uses top results for accurate responses.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/fusion_rag.ipynb) |\\n| Contextual RAG      | LangChain, Chromadb, Athina AI                    | Compresses retrieved documents to keep only relevant details for concise and accurate responses.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_tech',\n",
       "  'filename': 'rag-cookbooks-main/README.md'},\n",
       " {'start': 6000,\n",
       "  'chunk': 'rieves the full document if a part matches the query.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/parent_document_retriever.ipynb) |\\n| RAG fusion      | LangChain, LangSmith, Qdrant, Athina AI                    | Generates sub-queries, ranks documents with Reciprocal Rank Fusion, and uses top results for accurate responses.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/fusion_rag.ipynb) |\\n| Contextual RAG      | LangChain, Chromadb, Athina AI                    | Compresses retrieved documents to keep only relevant details for concise and accurate responses.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/contextual_rag.ipynb) |\\n| Rewrite Retrieve Read     | LangChain, Chromadb, Athina AI                    | Improves query, retrieves better data, and generates accurate answers.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/rewrite_retrieve_read.ipynb) |\\n| Unstructured RAG     | LangChain, LangGraph, FAISS, Athina AI, Unstructured                    | This method designed to handle documents that combine text, tables, and images.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/basic_unstructured_rag.ipynb) |\\n\\n## Agentic RAG Techniques‚öôÔ∏è\\nHere are the details of all the Agentic RAG techniques covered in this repository.\\n\\n| Technique                    | Tools                        | Description                                ',\n",
       "  'filename': 'rag-cookbooks-main/README.md'},\n",
       " {'start': 7000,\n",
       "  'chunk': 'niques/contextual_rag.ipynb) |\\n| Rewrite Retrieve Read     | LangChain, Chromadb, Athina AI                    | Improves query, retrieves better data, and generates accurate answers.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/rewrite_retrieve_read.ipynb) |\\n| Unstructured RAG     | LangChain, LangGraph, FAISS, Athina AI, Unstructured                    | This method designed to handle documents that combine text, tables, and images.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/basic_unstructured_rag.ipynb) |\\n\\n## Agentic RAG Techniques‚öôÔ∏è\\nHere are the details of all the Agentic RAG techniques covered in this repository.\\n\\n| Technique                    | Tools                        | Description                                                       | Notebooks |\\n|---------------------------------|------------------------------|--------------------------------------------------------------|-----------|\\n| Basic Agentic RAG      | LangChain, FAISS, Athina AI                    | Agentic RAG uses AI agents to find and generate answers using tools like vectordb and web searches.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/agentic_rag_techniques/basic_agentic_rag.ipynb) |\\n| Corrective RAG      | LangChain, LangGraph, Chromadb, Athina AI                    | Refines relevant documents, removes irrelevant ones or does the web search.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/agentic_rag_techniques/corrective_rag.ipynb) |\\n| Self RAG     | LangChain, LangGraph, FAISS, Athina AI                    | Re',\n",
       "  'filename': 'rag-cookbooks-main/README.md'},\n",
       " {'start': 8000,\n",
       "  'chunk': '                       | Notebooks |\\n|---------------------------------|------------------------------|--------------------------------------------------------------|-----------|\\n| Basic Agentic RAG      | LangChain, FAISS, Athina AI                    | Agentic RAG uses AI agents to find and generate answers using tools like vectordb and web searches.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/agentic_rag_techniques/basic_agentic_rag.ipynb) |\\n| Corrective RAG      | LangChain, LangGraph, Chromadb, Athina AI                    | Refines relevant documents, removes irrelevant ones or does the web search.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/agentic_rag_techniques/corrective_rag.ipynb) |\\n| Self RAG     | LangChain, LangGraph, FAISS, Athina AI                    | Reflects on retrieved data to ensure accurate and complete responses.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/agentic_rag_techniques/self_rag.ipynb) |\\n| Adaptive RAG      | LangChain, LangGraph, FAISS, Athina AI                    | Adjusts retrieval methods based on query type, using indexed data or web search.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/agentic_rag_techniques/adaptive_rag.ipynb) |\\n| ReAct RAG      | LangChain, LangGraph, FAISS, Athina AI                    |  System combining reasoning and retrieval for context-aware responses| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/agentic_rag_techniques/react_rag.ipynb) |\\n\\n## Demoüé¨\\nA quick demo of how eac',\n",
       "  'filename': 'rag-cookbooks-main/README.md'},\n",
       " {'start': 9000,\n",
       "  'chunk': \"flects on retrieved data to ensure accurate and complete responses.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/agentic_rag_techniques/self_rag.ipynb) |\\n| Adaptive RAG      | LangChain, LangGraph, FAISS, Athina AI                    | Adjusts retrieval methods based on query type, using indexed data or web search.| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/agentic_rag_techniques/adaptive_rag.ipynb) |\\n| ReAct RAG      | LangChain, LangGraph, FAISS, Athina AI                    |  System combining reasoning and retrieval for context-aware responses| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/athina-ai/rag-cookbooks/blob/main/agentic_rag_techniques/react_rag.ipynb) |\\n\\n## Demoüé¨\\nA quick demo of how each notebook works:\\n\\nhttps://github.com/user-attachments/assets/c6f17961-40a1-4cca-ab1f-2c8fa3d71a7a\\n\\n## Getting Startedüõ†Ô∏è\\nFirst, clone this repository by using the following command:\\n```bash\\ngit clone https://github.com/athina-ai/rag-cookbooks.git\\n```\\nNext, navigate to the project directory:\\n```bash\\ncd rag-cookbooks\\n```\\nOnce you are in the 'rag-cookbooks' directory, follow the detailed implementation for each technique.\\n\\n## Creators + Contributorsüë®üèª\\u200düíª\\n[![Contributors](https://contrib.rocks/image?repo=athina-ai/cookbooks)](https://github.com/athina-ai/cookbooks/graphs/contributors)\\n\\n## Contributingü§ù\\nIf you have a new technique or improvement to suggest, we welcome contributions from the community!\\n\\n## Licenseüìù\\nThis project is licensed under [MIT License](LICENSE)\",\n",
       "  'filename': 'rag-cookbooks-main/README.md'}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ef5e59-65d4-4cac-94ed-6b4d5cb92165",
   "metadata": {},
   "source": [
    "## 2 . Splitting by Paragraphs and Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b5e34010-9339-4c27-98c8-c90b0c4fead7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_markdown_by_level(text, level=2):\n",
    "    \"\"\"\n",
    "    Split markdown text by a specific header level.\n",
    "    \n",
    "    :param text: Markdown text as a string\n",
    "    :param level: Header level to split on\n",
    "    :return: List of sections as strings\n",
    "    \"\"\"\n",
    "    # This regex matches markdown headers\n",
    "    # For level 2, it matches lines starting with \"## \"\n",
    "    header_pattern = r'^(#{' + str(level) + r'} )(.+)$'\n",
    "    pattern = re.compile(header_pattern, re.MULTILINE)\n",
    "\n",
    "    # Split and keep the headers\n",
    "    parts = pattern.split(text)\n",
    "    \n",
    "    sections = []\n",
    "    for i in range(1, len(parts), 3):\n",
    "        # We step by 3 because regex.split() with\n",
    "        # capturing groups returns:\n",
    "        # [before_match, group1, group2, after_match, ...]\n",
    "        # here group1 is \"## \", group2 is the header text\n",
    "        header = parts[i] + parts[i+1]  # \"## \" + \"Title\"\n",
    "        header = header.strip()\n",
    "\n",
    "        # Get the content after this header\n",
    "        content = \"\"\n",
    "        if i+2 < len(parts):\n",
    "            content = parts[i+2].strip()\n",
    "\n",
    "        if content:\n",
    "            section = f'{header}\\n\\n{content}'\n",
    "        else:\n",
    "            section = header\n",
    "        sections.append(section)\n",
    "    \n",
    "    return sections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "34cc6c4e-2ef6-438c-8f8c-474ca0a5a103",
   "metadata": {},
   "outputs": [],
   "source": [
    "evidently_chunks = []\n",
    "\n",
    "for doc in evidently_docs:\n",
    "    doc_copy = doc.copy()\n",
    "    doc_content = doc_copy.pop('content')\n",
    "    sections = split_markdown_by_level(doc_content, level=2)\n",
    "    for section in sections:\n",
    "        section_doc = doc_copy.copy()\n",
    "        section_doc['section'] = section\n",
    "        evidently_chunks.append(section_doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a4c7d011-24de-4b95-855c-d3473adae93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(evidently_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98eb3d7b-a6ff-4fa8-b215-af689f92fac1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
